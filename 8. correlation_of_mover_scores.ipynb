{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "\n",
    "lang2mono = {'EN': 'bert-base-uncased',\n",
    "             'ID': 'indobert-base-uncased',\n",
    "             'FR': 'camembert-base',\n",
    "             'TR': 'bert-base-turkish-uncased',\n",
    "             'ZH': 'bert-base-chinese',\n",
    "             'RU': 'rubert-base-cased',\n",
    "             'DE': 'bert-base-german-dbmdz-uncased',\n",
    "             'ES': 'bert-base-spanish-wwm-uncased'}\n",
    "\n",
    "LANGS = ['EN', 'ID', 'FR', 'TR', 'ZH', 'RU', 'DE', 'ES']\n",
    "model = 'PG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_human_annotation(lang, types='focus'):\n",
    "    if types=='focus':\n",
    "        path_human = f'mturk/annotation_result/{lang}/human_focus_final.csv'\n",
    "    else:\n",
    "        assert types=='coverage'\n",
    "        path_human = f'mturk/annotation_result/{lang}/human_coverage_final.csv'\n",
    "    human = pd.read_csv(path_human)\n",
    "    return human\n",
    "\n",
    "def align(df, human_score, model):\n",
    "    human = []\n",
    "    machine = []\n",
    "    #print(df)\n",
    "    for idx, row in df.iterrows():\n",
    "        human.append(human_score[(human_score['model'] == model) & (human_score['id']==row['fnames'])]['score'].values[0])\n",
    "        machine.append(row['moverscore'])\n",
    "    return human, machine\n",
    "\n",
    "def read(lang, human_score, pretrained, model):\n",
    "    path_BERT = f'mover_score/{lang}--BERT--{pretrained}.csv'\n",
    "    path_PG = f'mover_score/{lang}--PG--{pretrained}.csv'\n",
    "        \n",
    "    humans = []; machines = []\n",
    "\n",
    "    if model == 'BERT':\n",
    "        df_BERT = pd.read_csv(path_BERT)\n",
    "        human, machine = align(df_BERT, human_score, 'BERT')\n",
    "        humans += human\n",
    "        machines += machine\n",
    "    elif model == 'PG':\n",
    "        df_PG = pd.read_csv(path_PG)\n",
    "        human, machine = align(df_PG, human_score, 'PG')\n",
    "        humans += human\n",
    "        machines += machine\n",
    "    \n",
    "    #print(humans)\n",
    "    #print(machines)\n",
    "    return pearsonr(humans, machines)[0], len(humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focus PG\n",
      "=============\n",
      "EN 135 bert-base-uncased 0.6164471195287589\n",
      "EN 135 bert-base-multilingual-cased 0.5740480716832725\n",
      "EN 135 bert-base-multilingual-uncased 0.6335447636526799\n",
      "EN 135 xlm-roberta-base 0.5572367589812162\n",
      "EN 135 xlm-roberta-large 0.5259846122405507\n",
      "\n",
      "ID 135 indobert-base-uncased 0.6685964663708452\n",
      "ID 135 bert-base-multilingual-cased 0.6214476866881169\n",
      "ID 135 bert-base-multilingual-uncased 0.65354736066805\n",
      "ID 135 xlm-roberta-base 0.6103843658495229\n",
      "ID 135 xlm-roberta-large 0.5744887968398797\n",
      "\n",
      "FR 135 camembert-base 0.6341290414054612\n",
      "FR 135 bert-base-multilingual-cased 0.7114173375145556\n",
      "FR 135 bert-base-multilingual-uncased 0.757150751203846\n",
      "FR 135 xlm-roberta-base 0.6001662754347832\n",
      "FR 135 xlm-roberta-large 0.6038136261126427\n",
      "\n",
      "TR 135 bert-base-turkish-uncased 0.8762992726882338\n",
      "TR 135 bert-base-multilingual-cased 0.8425000351887733\n",
      "TR 135 bert-base-multilingual-uncased 0.8754562378679195\n",
      "TR 135 xlm-roberta-base 0.858844380394457\n",
      "TR 135 xlm-roberta-large 0.8350149874305126\n",
      "\n",
      "ZH 135 bert-base-chinese 0.8037862034740352\n",
      "ZH 135 bert-base-multilingual-cased 0.7874017823488868\n",
      "ZH 135 bert-base-multilingual-uncased 0.789444637805361\n",
      "ZH 135 xlm-roberta-base 0.7306683120422397\n",
      "ZH 135 xlm-roberta-large 0.6187937789329675\n",
      "\n",
      "RU 135 rubert-base-cased 0.6490242845393226\n",
      "RU 135 bert-base-multilingual-cased 0.6036864229478672\n",
      "RU 135 bert-base-multilingual-uncased 0.5739465922436167\n",
      "RU 135 xlm-roberta-base 0.3241517574977398\n",
      "RU 135 xlm-roberta-large 0.2979871936407184\n",
      "\n",
      "DE 135 bert-base-german-dbmdz-uncased 0.8991930862951626\n",
      "DE 135 bert-base-multilingual-cased 0.8830039072397964\n",
      "DE 135 bert-base-multilingual-uncased 0.885824865577252\n",
      "DE 135 xlm-roberta-base 0.8618575573247038\n",
      "DE 135 xlm-roberta-large 0.8656427198835948\n",
      "\n",
      "ES 135 bert-base-spanish-wwm-uncased 0.6042112390231249\n",
      "ES 135 bert-base-multilingual-cased 0.7095681290060936\n",
      "ES 135 bert-base-multilingual-uncased 0.7409707748097034\n",
      "ES 135 xlm-roberta-base 0.7109904658851809\n",
      "ES 135 xlm-roberta-large 0.6314298305390225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LANGS = ['EN', 'ID', 'FR', 'TR', 'ZH', 'RU', 'DE', 'ES']\n",
    "\n",
    "# Focus\n",
    "print('Focus', model)\n",
    "print('=============')\n",
    "cors = {}\n",
    "for lang in LANGS:\n",
    "    human_score = read_human_annotation(lang, 'focus')\n",
    "    for pretrained in [ lang2mono[lang], 'bert-base-multilingual-cased', 'bert-base-multilingual-uncased', \\\n",
    "                      'xlm-roberta-base', 'xlm-roberta-large']:    \n",
    "        cor, num = read(lang, human_score, pretrained, model)\n",
    "        print(lang, num, pretrained, cor)    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage PG\n",
      "=============\n",
      "EN 135 bert-base-uncased 0.5744128253999503\n",
      "EN 135 bert-base-multilingual-cased 0.531324766684457\n",
      "EN 135 bert-base-multilingual-uncased 0.5789456830210102\n",
      "EN 135 xlm-roberta-base 0.5638916955072275\n",
      "EN 135 xlm-roberta-large 0.5227044211163876\n",
      "\n",
      "ID 135 indobert-base-uncased 0.6487534517968864\n",
      "ID 135 bert-base-multilingual-cased 0.6669593678347698\n",
      "ID 135 bert-base-multilingual-uncased 0.6806911674137139\n",
      "ID 135 xlm-roberta-base 0.60918956550856\n",
      "ID 135 xlm-roberta-large 0.6225022599203025\n",
      "\n",
      "FR 135 camembert-base 0.6258059520381745\n",
      "FR 135 bert-base-multilingual-cased 0.6772067984519621\n",
      "FR 135 bert-base-multilingual-uncased 0.739755021166638\n",
      "FR 135 xlm-roberta-base 0.5195971110985669\n",
      "FR 135 xlm-roberta-large 0.49871865824803285\n",
      "\n",
      "TR 135 bert-base-turkish-uncased 0.7315959815042467\n",
      "TR 135 bert-base-multilingual-cased 0.713899653879187\n",
      "TR 135 bert-base-multilingual-uncased 0.7152166224245092\n",
      "TR 135 xlm-roberta-base 0.6818916580799683\n",
      "TR 135 xlm-roberta-large 0.6612647162648362\n",
      "\n",
      "ZH 135 bert-base-chinese 0.7935095927234318\n",
      "ZH 135 bert-base-multilingual-cased 0.7694115967239776\n",
      "ZH 135 bert-base-multilingual-uncased 0.7586020462753161\n",
      "ZH 135 xlm-roberta-base 0.7090123210897281\n",
      "ZH 135 xlm-roberta-large 0.5854430232756553\n",
      "\n",
      "RU 135 rubert-base-cased 0.676215922764047\n",
      "RU 135 bert-base-multilingual-cased 0.6037951163051278\n",
      "RU 135 bert-base-multilingual-uncased 0.577437176275363\n",
      "RU 135 xlm-roberta-base 0.30778878074202654\n",
      "RU 135 xlm-roberta-large 0.31030838020083873\n",
      "\n",
      "DE 135 bert-base-german-dbmdz-uncased 0.8640415759546937\n",
      "DE 135 bert-base-multilingual-cased 0.8240318022437629\n",
      "DE 135 bert-base-multilingual-uncased 0.8420432153717845\n",
      "DE 135 xlm-roberta-base 0.8231134071010298\n",
      "DE 135 xlm-roberta-large 0.8205524761829364\n",
      "\n",
      "ES 135 bert-base-spanish-wwm-uncased 0.5451918046806639\n",
      "ES 135 bert-base-multilingual-cased 0.62569891156549\n",
      "ES 135 bert-base-multilingual-uncased 0.6372998791944536\n",
      "ES 135 xlm-roberta-base 0.6190632076549232\n",
      "ES 135 xlm-roberta-large 0.48719568430303095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Coverage\n",
    "print('Coverage', model)\n",
    "print('=============')\n",
    "cors = {}\n",
    "for lang in LANGS:\n",
    "    human_score = read_human_annotation(lang, 'coverage')\n",
    "    for pretrained in [ lang2mono[lang], 'bert-base-multilingual-cased', 'bert-base-multilingual-uncased', \\\n",
    "                      'xlm-roberta-base', 'xlm-roberta-large']: \n",
    "        cor, num = read(lang, human_score, pretrained, model)\n",
    "        print(lang, num, pretrained, cor)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
